{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Instalar Dependencias\n"
      ],
      "metadata": {
        "id": "r7a1u0s2SEhD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C0rQs7_RR6jN"
      },
      "outputs": [],
      "source": [
        "!pip install fastapi uvicorn pyngrok nest_asyncio\n",
        "!pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n",
        "!pip install --no-deps xformers trl peft accelerate bitsandbytes\n",
        "!pip install -q -U qwen-tts"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Accedemos al drive donde se guardo el modelo / sino se debe cargar la carpeta"
      ],
      "metadata": {
        "id": "Z_-3yZHf3CX0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7MpgDXj9svPQ",
        "outputId": "5699b98d-90f7-41d7-a5fb-5bbb989422a7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prueba que todo este bien\n",
        "#!python api_qa_sunat.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cgXd8ksE2ZmE",
        "outputId": "6a558863-bc70-4266-8006-24458161c1ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
            "2026-02-01 01:41:28.093989: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1769910088.114934    5976 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1769910088.121592    5976 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1769910088.137640    5976 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769910088.137665    5976 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769910088.137669    5976 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769910088.137674    5976 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-02-01 01:41:28.142441: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n",
            "\n",
            "********\n",
            "Warning: flash-attn is not installed. Will only run the manual PyTorch version. Please install flash-attn for faster inference.\n",
            "********\n",
            " \n",
            "/bin/sh: 1: sox: not found\n",
            "[sox|WARNING]SoX could not be found!\n",
            "\n",
            "    If you do not have SoX, proceed here:\n",
            "     - - - http://sox.sourceforge.net/ - - -\n",
            "\n",
            "    If you do (or think that you should) have SoX, double-check your\n",
            "    path variables.\n",
            "    \n",
            "Cargando modelo finatuning SUNAT....\n",
            "==((====))==  Unsloth 2026.1.4: Fast Qwen3 patching. Transformers: 4.57.3.\n",
            "   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.9.0+cu126. CUDA: 7.5. CUDA Toolkit: 12.6. Triton: 3.5.0\n",
            "\\        /    Bfloat16 = FALSE. FA [Xformers = None. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
            "model.safetensors.index.json: 144kB [00:00, 221MB/s]\n",
            "model-00001-of-00002.safetensors: 100% 4.98G/4.98G [00:48<00:00, 103MB/s]\n",
            "model-00002-of-00002.safetensors: 100% 2.50G/2.50G [00:21<00:00, 117MB/s]\n",
            "Loading checkpoint shards: 100% 2/2 [00:29<00:00, 14.89s/it]\n",
            "generation_config.json: 100% 237/237 [00:00<00:00, 1.59MB/s]\n",
            "Unsloth 2026.1.4 patched 36 layers with 36 QKV layers, 36 O layers and 36 MLP layers.\n",
            "Modelo SUNAT cargado exitosamente.\n",
            "Cargando Tu Modelo TTS del curso...\n",
            "config.json: 4.49kB [00:00, 1.54MB/s]\n",
            "model.safetensors: 100% 1.83G/1.83G [00:13<00:00, 138MB/s]\n",
            "generation_config.json: 100% 245/245 [00:00<00:00, 1.56MB/s]\n",
            "config.json: 2.34kB [00:00, 12.1MB/s]\n",
            "configuration.json: 100% 76.0/76.0 [00:00<00:00, 545kB/s]\n",
            "speech_tokenizer/model.safetensors: 100% 682M/682M [00:05<00:00, 135MB/s]\n",
            "preprocessor_config.json: 100% 234/234 [00:00<00:00, 1.42MB/s]\n",
            "preprocessor_config.json: 100% 127/127 [00:00<00:00, 176kB/s]\n",
            "tokenizer_config.json: 7.34kB [00:00, 26.6MB/s]\n",
            "vocab.json: 2.78MB [00:00, 64.5MB/s]\n",
            "merges.txt: 1.67MB [00:00, 136MB/s]\n",
            "Modelo Base cargado\n",
            "\u001b[32mINFO\u001b[0m:     Started server process [\u001b[36m5976\u001b[0m]\n",
            "\u001b[32mINFO\u001b[0m:     Waiting for application startup.\n",
            "\u001b[32mINFO\u001b[0m:     Application startup complete.\n",
            "\u001b[32mINFO\u001b[0m:     Uvicorn running on \u001b[1mhttp://0.0.0.0:8000\u001b[0m (Press CTRL+C to quit)\n",
            "\u001b[32mINFO\u001b[0m:     Shutting down\n",
            "\u001b[32mINFO\u001b[0m:     Waiting for application shutdown.\n",
            "\u001b[32mINFO\u001b[0m:     Application shutdown complete.\n",
            "\u001b[32mINFO\u001b[0m:     Finished server process [\u001b[36m5976\u001b[0m]\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ejecutamos usando ngrok para usarlo fuera del entorno de colab\n",
        "\n",
        "Puede tardar varios minutos en descargar y configurar los modelos"
      ],
      "metadata": {
        "id": "X35wiLDS4CLt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pyngrok import ngrok\n",
        "import uvicorn\n",
        "import threading\n",
        "\n",
        "# Configura token Ngrok\n",
        "NGROK_TOKEN = \"API_NGROK\"\n",
        "ngrok.set_auth_token(NGROK_TOKEN)\n",
        "\n",
        "os.system(\"kill -9 $(pgrep uvicorn)\")\n",
        "ngrok.kill()\n",
        "\n",
        "# Abrir el tÃºnel al puerto 8000\n",
        "public_url = ngrok.connect(8000).public_url\n",
        "print(f\"\\nðŸš€ API LISTA PARA USAR EN POSTMAN: {public_url}/v1/chat\")\n",
        "print(f\"\\nðŸŽ§ API DE VOZ LISTA: {public_url}/v1/chat/audio\")\n",
        "print(f\"\\nðŸ“„ DocumentaciÃ³n (Swagger): {public_url}/docs\\n\")\n",
        "\n",
        "# Ejecutar el script del api\n",
        "def run_server():\n",
        "    os.system(\"python api_qa_sunat.py > server.log 2>&1\")\n",
        "\n",
        "thread = threading.Thread(target=run_server)\n",
        "thread.start()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cf5HKsv5Dpwg",
        "outputId": "ccd5a38d-7b82-40d3-9685-8f837ece3927"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸš€ API LISTA PARA USAR EN POSTMAN: https://a5c56e183dd4.ngrok-free.app/v1/chat\n",
            "\n",
            "ðŸŽ§ API DE VOZ LISTA: https://a5c56e183dd4.ngrok-free.app/v1/chat/audio\n",
            "\n",
            "ðŸ“„ DocumentaciÃ³n (Swagger): https://a5c56e183dd4.ngrok-free.app/docs\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lNGx_qti6fQU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}